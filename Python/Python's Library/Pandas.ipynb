{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Starting with Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Basics Of Pandas***\n",
    "    -- Creating Objects\n",
    "    -- Viewing Data\n",
    "    -- Selection and Slicing\n",
    "    -- Operations\n",
    "    -- Manipulating Data\n",
    "    -- Grouping Data\n",
    "    -- Merging, Joining, Concatenating and Comparing\n",
    "    -- Working with Date and Time\n",
    "    -- Working with Text Data\n",
    "    -- Working with CSV and Excel files\n",
    "    -- Visualization\n",
    "    -- Applications and Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependency\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Creating Objects of Pandas Dataframe and Series***\n",
    "    --> datas in list format, dictionary format or other\n",
    "```\n",
    "    dataframe = pd.DataFrame(datas)\n",
    "``` \n",
    "    --> datas in list format, dictionary format or other\n",
    "```\n",
    "    series = pd.Series(datas)\n",
    "``` \n",
    "    --> datas load from csv files\n",
    "```\n",
    "    df_csv = pd.read_csv(datas)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # # Creating Objects\n",
    "# # Dataframe Creating\n",
    "# Empty Dataframe\n",
    "df_1 = pd.DataFrame()\n",
    "print(\"DataFrame : \", df_1)\n",
    "print(\"DataFrame Size : \", df_1.size)\n",
    "print(\"DataFrame Shape : \", df_1.shape)\n",
    "print(\"DataFrame Types : \", df_1.dtypes)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# Dataframe from List without Column name\n",
    "df_2 = pd.DataFrame([['Apple', 'Mango', 'Grapes', 'Amrut'], [12, 24, 36, 48]])\n",
    "print(\"DataFrame : \", df_2)\n",
    "print(\"DataFrame Size : \", df_2.size)\n",
    "print(\"DataFrame Shape : \", df_2.shape)\n",
    "print(\"DataFrame Types : \", df_2.dtypes)\n",
    "print()\n",
    "\n",
    "df_3 = pd.DataFrame(['Apple', 'Mango', 'Grapes', 'Amrut'], [12, 24, 36, 48])\n",
    "print(\"DataFrame : \", df_3)\n",
    "print(\"DataFrame Size : \", df_3.size)\n",
    "print(\"DataFrame Shape : \", df_3.shape)\n",
    "print(\"DataFrame Types : \", df_3.dtypes)\n",
    "print()\n",
    "\n",
    "df_4 = pd.DataFrame([['Apple', 12], ['Mango', 24], ['Grapes', 36], ['Amrut', 48]])\n",
    "print(\"DataFrame : \", df_3)\n",
    "print(\"DataFrame Size : \", df_4.size)\n",
    "print(\"DataFrame Shape : \", df_4.shape)\n",
    "print(\"DataFrame Types : \", df_4.dtypes)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# Dataframe from List with Column name\n",
    "df_5 = pd.DataFrame({'Fruits' : ['Apple', 'Mango', 'Grapes', 'Amrut'], \n",
    "                     'Score' : [12, 24, 36, 48]})\n",
    "print(\"DataFrame : \\n\", df_5)\n",
    "print(\"DataFrame Size : \", df_5.size)\n",
    "print(\"DataFrame Shape : \", df_5.shape)\n",
    "print(\"DataFrame Types : \\n\", df_5.dtypes)\n",
    "print()\n",
    "\n",
    "df_6 = pd.DataFrame([['Apple', 12], ['Mango', 24], ['Grapes', 36], ['Amrut', 48]], columns=['Fruits', 'Score'])\n",
    "print(\"DataFrame : \\n\", df_6)\n",
    "print(\"DataFrame Size : \", df_6.size)\n",
    "print(\"DataFrame Shape : \", df_6.shape)\n",
    "print(\"DataFrame Types : \\n\", df_6.dtypes)\n",
    "print()\n",
    "\n",
    "df_7 = pd.DataFrame([{'a': 1, 'b': 2, 'c': 3},{'a': 10, 'b': 20, 'c': 30}])\n",
    "print(\"DataFrame : \\n\", df_7)\n",
    "print(\"DataFrame Size : \", df_7.size)\n",
    "print(\"DataFrame Shape : \", df_7.shape)\n",
    "print(\"DataFrame Types : \\n\", df_7.dtypes)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# Dataframe from List with Column name with index\n",
    "df_8 = pd.DataFrame([['Apple', 12], ['Mango', 24], ['Grapes', 36], ['Amrut', 48]], \n",
    "                    columns=['Fruits', 'Score'],\n",
    "                    index=['id1', 'id2', 'id3', 'id4'])\n",
    "print(\"DataFrame : \\n\", df_8)\n",
    "print(\"DataFrame Size : \", df_8.size)\n",
    "print(\"DataFrame Shape : \", df_8.shape)\n",
    "print(\"DataFrame Types : \\n\", df_8.dtypes)\n",
    "print()\n",
    "\n",
    "df_9 = pd.DataFrame(list(zip(['Apple', 'Mango', 'Grapes', 'Amrut'], [12, 24, 36, 48])), \n",
    "                    columns=['Fruits', 'Score'],\n",
    "                    index=['id1', 'id2', 'id3', 'id4'])\n",
    "print(\"DataFrame : \\n\", df_9)\n",
    "print(\"DataFrame Size : \", df_9.size)\n",
    "print(\"DataFrame Shape : \", df_9.shape)\n",
    "print(\"DataFrame Types : \\n\", df_9.dtypes)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Series Creating\n",
    "# Empty Series\n",
    "ds_1 = pd.Series()\n",
    "print(\"DataSeries : \", ds_1)\n",
    "print(\"DataSeries Size : \", ds_1.size)\n",
    "print(\"DataSeries Shape : \", ds_1.shape)\n",
    "print(\"DataSeries Types : \", ds_1.dtypes)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# DataSeries from List without Column name\n",
    "ds_2 = pd.Series([['Apple', 'Mango', 'Grapes', 'Amrut'], [12, 24, 36, 48]])\n",
    "print(\"DataSeries : \\n\", ds_2)\n",
    "print(\"DataSeries Size : \", ds_2.size)\n",
    "print(\"DataSeries Shape : \", ds_2.shape)\n",
    "print(\"DataSeries Types : \", ds_2.dtypes)\n",
    "print()\n",
    "\n",
    "ds_3 = pd.Series([['Apple', 12], ['Mango', 24], ['Grapes', 36], ['Amrut', 48]])\n",
    "print(\"DataSeries : \\n\", ds_3)\n",
    "print(\"DataSeries Size : \", ds_3.size)\n",
    "print(\"DataSeries Shape : \", ds_3.shape)\n",
    "print(\"DataSeries Types : \", ds_3.dtypes)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# DataSeries from List with Index name\n",
    "ds_5 = pd.Series([['Apple', 'Mango', 'Grapes', 'Amrut'], [12, 24, 36, 48]], index=['Fruits', 'Num'])\n",
    "print(\"DataSeries : \\n\", ds_5)\n",
    "print(\"DataSeries Size : \", ds_5.size)\n",
    "print(\"DataSeries Shape : \", ds_5.shape)\n",
    "print(\"DataSeries Types : \", ds_5.dtypes)\n",
    "print()\n",
    "\n",
    "ds_6 = pd.Series(['Apple', 'Mango', 'Grapes', 'Amrut'], [12, 24, 36, 48])\n",
    "print(\"DataSeries : \\n\", ds_6)\n",
    "print(\"DataSeries Size : \", ds_6.size)\n",
    "print(\"DataSeries Shape : \", ds_6.shape)\n",
    "print(\"DataSeries Types : \", ds_6.dtypes)\n",
    "print()\n",
    "\n",
    "ds_7 = pd.Series(10, index=[0, 1, 2, 3, 4, 5])\n",
    "print(\"DataSeries : \\n\", ds_7)\n",
    "print(\"DataSeries Size : \", ds_7.size)\n",
    "print(\"DataSeries Shape : \", ds_7.shape)\n",
    "print(\"DataSeries Types : \", ds_7.dtypes)\n",
    "print()\n",
    "\n",
    "ds_8 = pd.Series({'Aam': 10, 'Angur': 20, 'Amrut': 30})\n",
    "print(\"DataSeries : \\n\", ds_8)\n",
    "print(\"DataSeries Size : \", ds_8.size)\n",
    "print(\"DataSeries Shape : \", ds_8.shape)\n",
    "print(\"DataSeries Types : \", ds_8.dtypes)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Viewing Data***\n",
    "    --> Show top of the data, n - number of rows\n",
    "```\n",
    "    dataframe.head(n)\n",
    "``` \n",
    "    --> Show bottom of the Data, n - number of rows\n",
    "```\n",
    "    dataframe.tail(n)\n",
    "``` \n",
    "    --> Describes Data, parameter - (percentiles, includes, ..)\n",
    "```\n",
    "    dataframe.describe(paramenter)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Viewing Data\n",
    "data = pd.read_csv(\"/Coding/Python's Library/Data/nba.csv\")\n",
    "print(data)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# # Printing top 10 data\n",
    "data_top = data.head(10)\n",
    "print(data_top)\n",
    "print()\n",
    "\n",
    "# # Printing top 10 data\n",
    "data_top_col = data['Name']\n",
    "data_top = data_top_col.head(10)\n",
    "print(data_top)\n",
    "print()\n",
    "\n",
    "# # Printing bottom 10 data\n",
    "data_bottom = data.tail(10)\n",
    "print(data_bottom)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# # Printing bottom 10 data\n",
    "data_bottom_col = data['Name']\n",
    "data_bottom = data_bottom_col.tail(10)\n",
    "print(data_bottom)\n",
    "print()\n",
    "\n",
    "# # Printing description of data\n",
    "data_Desc = data.describe()\n",
    "print(data_Desc)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# percentile list\n",
    "perc = [.20, .40, .60, .80]\n",
    "# list of dtypes to include\n",
    "include = ['object', 'float', 'int']\n",
    "# calling describe method\n",
    "data_Desc_perc = data.describe(percentiles=perc, include=include)\n",
    "print(data_Desc_perc)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Selecting And Slicing Dataframe and Series***\n",
    "    --> By Using Direct Rows and Column\n",
    "    --> Deals with Rows By using .iloc[]\n",
    "    --> Deals with Rows By using .loc[]\n",
    "    --> By Index Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Selection and Slicing\n",
    "# # Dealing with Rows and Columns in Pandas DataFrame\n",
    "data = pd.read_csv(\"/Coding/Python's Library/Data/nba.csv\", index_col =\"Name\" )\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "# Fetch dataset by their columns\n",
    "print(data[['Height', 'Age']])\n",
    "print()\n",
    "\n",
    "# Drop the column\n",
    "data.drop([\"Team\", \"Weight\"], axis = 1, inplace = True)\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "# Add row to dataframe\n",
    "add_row = pd.DataFrame({'Name':'Geeks', 'Team':'Boston', 'Number':3,\n",
    "                        'Position':'PG', 'Age':33, 'Height':'6-2',\n",
    "                        'Weight':189, 'College':'MIT', 'Salary':99999},index =[0])\n",
    "data_add = pd.concat([add_row, data]).reset_index(drop = True)\n",
    "print(data_add)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# Drop the Row\n",
    "data.drop([\"Avery Bradley\", \"John Holland\", \"R.J. Hunter\",\"R.J. Hunter\"], inplace = True)\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "# # Pandas Extracting Rows using loc operation\n",
    "first = data.loc[\"Avery Bradley\"]\n",
    "second = data.loc[\"R.J. Hunter\"]\n",
    "print(first, '\\n\\n\\n', second)\n",
    "print()\n",
    "\n",
    "# retrieving rows\n",
    "rows = data.loc[[\"Avery Bradley\", \"R.J. Hunter\"]]\n",
    "print(rows)\n",
    "print()\n",
    "print(type(rows))\n",
    "print()\n",
    "\n",
    "# retrieving rows for two\n",
    "rows = data.loc[\"Avery Bradley\":\"Isaiah Thomas\"]\n",
    "print(rows)\n",
    "print()\n",
    "\n",
    "# # Pandas Extracting Rows using iloc operation\n",
    "first = data.iloc[1]\n",
    "print(first)\n",
    "print()\n",
    "\n",
    "# retrieving rows for two\n",
    "rows = data.iloc[3:8]\n",
    "print(rows)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "# # Pandas Series.str.slice()\n",
    "# removing null values to avoid errors \n",
    "data.dropna(inplace = True) \n",
    "# start stop and step variables\n",
    "start, stop, step = 0, -2, 1\n",
    "data[\"Salary\"]= data[\"Salary\"].astype(str)\n",
    "data[\"Salary (int)\"]= data[\"Salary\"].str.slice(start, stop, step)\n",
    "print(data.head(10))\n",
    "print()\n",
    "\n",
    "# # Column Slicing\n",
    "data_an = pd.DataFrame({\n",
    "    \"a\": [1, 2, 3, 4, 5, 6, 7],\n",
    "    \"b\": [2, 3, 4, 2, 3, 4, 5],\n",
    "    \"c\": [3, 4, 5, 2, 3, 4, 5],\n",
    "    \"d\": [4, 5, 6, 2, 3, 4, 5],\n",
    "    \"e\": [5, 6, 7, 2, 3, 4, 5]\n",
    "    })\n",
    "print(data_an)\n",
    "print()\n",
    "print(data_an.reindex(columns=['b', 'c']))\n",
    "print()\n",
    "print(data_an.loc[:, \"b\":\"d\":2])\n",
    "print()\n",
    "print(data_an.iloc[:, 1:3:1])\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Some Basic Operations in Pandas***\n",
    "    --> Apply any function to the column by .apply()\n",
    "```\n",
    "    dataframe['Column'].apply(Function, convert_dtype=True, args=())\n",
    "``` \n",
    "    --> Apply some aggregate function like ['sum', 'mul'] so on.\n",
    "```\n",
    "    dataframe.aggregate(func, axis=0, *args, **kwargs)\n",
    "```\n",
    "    --> Finding mean of the numeric dataframe same as mad\n",
    "```\n",
    "    dataframe.mean(axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
    "    dataframe.mad(axis=None, skipna=None, level=None)\n",
    "\n",
    "    series.mean(axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
    "    series.mad(axis=None, skipna=None, level=None)\n",
    "```\n",
    "    --> Finding Standard Error and Value_count in series.\n",
    "```\n",
    "    dataframe.sem(axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
    "    series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Operations\n",
    "# # Using apply operation to Dataframe and Series.\n",
    "data = pd.read_csv('Data/Stock.csv')\n",
    "data_op = data.squeeze()\n",
    "\n",
    "# # Syntax : data_op.apply(func, convert_dtype=True, args=())\n",
    "# defining function to check price\n",
    "def fun(num):\n",
    "    if int(num)<29:\n",
    "        return \"LOW CLOSE\"\n",
    "    elif int(num)>= 29 and int(num)<30:\n",
    "        return \"NORMAL CLOSE\"\n",
    "    else:\n",
    "        return \"HIGH CLOSE\"\n",
    "\n",
    "# passing function to apply and storing returned series in new\n",
    "data_op_n1 = data_op['Close'].apply(fun)\n",
    "print(data_op_n1)\n",
    "print()\n",
    "\n",
    "data_op_n2 = data_op['High'].apply(lambda num : num + 5)\n",
    "print(data_op_n2)\n",
    "print()\n",
    "print(\"===================================================================================== \")\n",
    "print()\n",
    "\n",
    "## Apply function to every row in a Pandas DataFrame\n",
    "# --> Function to add\n",
    "def add(a, b, c):\n",
    "    return a + b + c\n",
    "\n",
    "data = {\n",
    "        'A':[1, 2, 3],\n",
    "        'B':[4, 5, 6],\n",
    "        'C':[7, 8, 9]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "df['Add'] = df.apply(lambda row : add(row['A'], row['B'], row['C']), axis = 1)\n",
    "# df['Add'] = df.apply(np.sum, axis = 1)\n",
    "print('\\nAfter Applying Function: ')\n",
    "print(df)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# --> Normalize DataFrame\n",
    "def normalize(x, y):\n",
    "    norm = ((x - np.mean([x, y])) / (max(x, y) - min(x, y)))\n",
    "    return norm\n",
    "\n",
    "data = {\n",
    "    'X':[1, 2, 3],\n",
    "    'Y':[45, 65, 89]\n",
    "    }\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)    \n",
    "df['X'] = df.apply(lambda row : normalize(row['X'], row['Y']), axis = 1)\n",
    "\n",
    "print('\\nNormalized:')\n",
    "print(df)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# --> Generate Range\n",
    "def generate_range(n):\n",
    "    n = int(n)\n",
    "    lower_limit = n//10 * 10\n",
    "    upper_limit = lower_limit + 10\n",
    "    return str(str(lower_limit) + '-' + str(upper_limit))\n",
    "\n",
    "def replace(row):\n",
    "    for i, item in enumerate(row):\n",
    "        row[i] = generate_range(item)\n",
    "    return row\n",
    "\n",
    "data = {\n",
    "    'A':[0, 2, 3],\n",
    "    'B':[4, 15, 6],\n",
    "    'C':[47, 8, 19]\n",
    "    }\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\\n\", df)    \n",
    "df = df.apply(lambda row : replace(row))\n",
    "\n",
    "print('\\nRange Showing Like that:')\n",
    "print(df)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# apply on Series and change value\n",
    "series_op = pd.Series(['New York', 'Chicago', 'Toronto', 'Lisbon', 'Rio'])\n",
    "index_ = ['City 1', 'City 2', 'City 3', 'City 4', 'City 5']\n",
    "series_op.index = index_\n",
    "print(series_op)\n",
    "print()\n",
    "\n",
    "series_op_n = series_op.apply(lambda x : 'Montreal' if x =='Rio' else x )\n",
    "print(series_op_n)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "series_op = pd.Series([11, 21, 8, 18, 65, 18, 32, 10, 5, 32, None])\n",
    "index_ = pd.date_range('2010-10-09 08:45', periods = 11, freq ='Y')\n",
    "series_op.index = index_\n",
    "print(series_op)\n",
    "print()\n",
    "\n",
    "series_op_n = series_op.apply(lambda x : True if x>30 else False)\n",
    "print(series_op_n)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pandas provide a method to make Calculation of MAD (Mean Absolute Deviation) very easy.***\n",
    "***MAD is defined as average distance between each value and mean.***\n",
    "\n",
    "    --> The formula used to calculate MAD is:\n",
    "\n",
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # Pandas dataframe.aggregate()\n",
    "data = pd.read_csv('Data/nba.csv')\n",
    "print(data[:10])\n",
    "print()\n",
    "\n",
    "# Applying aggregation across all the columns\n",
    "# sum and min will be found for each\n",
    "# numeric type column in df dataframe\n",
    "print(data['Number'].aggregate(['sum', 'min']))\n",
    "print()\n",
    "\n",
    "# We are going to find aggregation for these columns\n",
    "print(data.aggregate({\n",
    "    \"Number\":['sum', 'min'],\n",
    "    \"Age\":['max', 'min'],\n",
    "    \"Weight\":['min', 'sum'],\n",
    "    \"Salary\":['sum']\n",
    "    }))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # DataFrame.mean() Same for Series.mean()\n",
    "# # DataFrame.mad() Same for Series.mad() --> tends for Mean Absolute Deviation\n",
    "# # DataFrame.sem() Same for Series.sem() --> tends for Atandard Error of the Mean\n",
    "df_mean = pd.DataFrame({\n",
    "    \"A\":[12, 4, 5, 44, 1],\n",
    "    \"B\":[5, 2, 54, 3, 2],\n",
    "    \"C\":[20, 16, 7, 3, 8],\n",
    "    \"D\":[14, 3, 17, 2, 6]\n",
    "    })\n",
    "print(df_mean)\n",
    "print()\n",
    "\n",
    "# Even if we do not specify axis = 0,\n",
    "# the method will return the mean over\n",
    "# the index axis by default\n",
    "print(df_mean.mean(axis = 0))\n",
    "print(df_mean.sem(axis = 0))\n",
    "print()\n",
    "\n",
    "df_mean = pd.DataFrame({\n",
    "    \"A\":[12, 4, 5, None, 1],\n",
    "    \"B\":[7, 2, 54, 3, None],\n",
    "    \"C\":[20, 16, 11, 3, 8],\n",
    "    \"D\":[14, 3, None, 2, 6]\n",
    "    })\n",
    "\n",
    "# skip the Na values while finding the mean\n",
    "print(df_mean.mean(axis = 1, skipna = True))\n",
    "print(df_mean.sem(axis = 1, skipna = True))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# # Value count function\n",
    "series_vc = pd.Series(['New York', 'Chicago', 'Toronto', 'Lisbon', 'Rio', 'Chicago', 'Lisbon'])\n",
    "print(series_vc)\n",
    "print()\n",
    "\n",
    "print(series_vc.value_counts())\n",
    "print()\n",
    "\n",
    "index = pd.Index(['Harry', 'Mike', 'Arther', 'Nick', 'Harry', 'Arther'], name ='Student')\n",
    "print(index)\n",
    "print()\n",
    "\n",
    "print(index.value_counts())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Applying Lambda functions to Pandas Dataframe\n",
    "values= [['Rohan',455],['Elvish',250],['Deepak',495],['Soni',400],['Radhika',350],['Vansh',450]]\n",
    "df_lamb = pd.DataFrame(values,columns=['Name','Total_Marks'])\n",
    "print(df_lamb)\n",
    "print()\n",
    " \n",
    "# --> Applying lambda function to find percentage of 'Total_Marks' column using df.assign()\n",
    "df_lamb_n = df_lamb.assign(Percentage = lambda x: (x['Total_Marks'] /500 * 100))\n",
    "print(df_lamb_n)\n",
    "print()\n",
    "\n",
    "values_list = [[15, 2.5, 100], [20, 4.5, 50], [25, 5.2, 80],\n",
    "               [45, 5.8, 48], [40, 6.3, 70], [41, 6.4, 90],\n",
    "               [51, 2.3, 111]]\n",
    "df_lamb_1 = pd.DataFrame(values_list, columns=['Field_1', 'Field_2', 'Field_3'])\n",
    "print(df_lamb_1)\n",
    "print()\n",
    "\n",
    "# --> Applying lambda function to find the product of 3 columns using df.assign()\n",
    "df_lamb_n1 = df_lamb_1.assign(Product=lambda x: (x['Field_1'] * x['Field_2'] * x['Field_3']))\n",
    "print(df_lamb_n1)\n",
    "print()\n",
    "\n",
    "values_list = [[15, 2.5, 100], [20, 4.5, 50], [25, 5.2, 80],\n",
    "               [45, 5.8, 48], [40, 6.3, 70], [41, 6.4, 90],\n",
    "               [51, 2.3, 111]]\n",
    "df_lamb_2 = pd.DataFrame(values_list, columns=['Field_1', 'Field_2', 'Field_3'],\n",
    "                  index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "print(df_lamb_2)\n",
    "print()\n",
    "\n",
    "# --> Apply function numpy.square() to square the values of one row only i.e. row with index name 'd'\n",
    "df_lamb_n2 = df_lamb_2.apply(lambda x: np.square(x) if x.name == 'd' else x, axis=1)\n",
    "print(df_lamb_n2)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Manipulation Of Data***\n",
    "    --> Inserting column By using .insert() function and .assign() function\n",
    "```\n",
    "    dataframe.insert(loc, column, value, allow_duplicates = False)\n",
    "    dataframe.assign(**kwargs)\n",
    "``` \n",
    "    --> Droping Data Rows or column by .drop() function and .truncate() function\n",
    "```\n",
    "    dataframe.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors=’raise’)\n",
    "    dataframe.truncate(before=None, after=None, axis=None, copy=True)\n",
    "    \n",
    "    series.truncate(before=None, after=None, axis=None, copy=True)\n",
    "``` \n",
    "    --> Iterative function in dataframe\n",
    "```\n",
    "    dataframe.iterrows()\n",
    "    dataframe.iteritems()\n",
    "    dataframe.itertuples()\n",
    "``` \n",
    "    --> Sorting Dataframe Data by using .sort_values()\n",
    "```\n",
    "    dataframe.sort_values(by, axis=0, ascending=True, inplace=False, kind=’quicksort’, na_position=’last’)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # # MANIPULATING DATA\n",
    "# # Adding New Column\n",
    "data = {'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "        'Height': [5.1, 6.2, 5.1, 5.2],\n",
    "        'Qualification': ['Msc', 'MA', 'Msc', 'Msc']}\n",
    "df_manip = pd.DataFrame(data)\n",
    "print(df_manip)\n",
    "print()\n",
    "\n",
    "df_manip[\"Address\"] = ['Delhi', 'Bangalore', 'Chennai', 'Patna'] # Add new column as Address\n",
    "df_manip.insert(2, \"Address\", ['Delhi', 'Bangalore', 'Chennai', 'Patna'])\n",
    "df_manip = df_manip.assign(address=['Delhi', 'Bangalore', 'Chennai', 'Patna'])\n",
    "print(df_manip)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Delete rows/columns from DataFrame using Pandas.drop()\n",
    "data = pd.read_csv('Data/nba.csv', index_col=\"Name\")\n",
    "print(data.head(5))\n",
    "print()\n",
    "\n",
    "data.drop([\"Avery Bradley\", \"John Holland\", \"R.J. Hunter\"], inplace = True) # Drop passed value data\n",
    "print(data.head())\n",
    "print()\n",
    "\n",
    "data.drop([\"Team\", \"Weight\"], axis = 1, inplace = True) # Drop Passed Column Data\n",
    "print(data.head(5))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Pandas DataFrame.truncate, Series.truncate --> Used to delete data, before and after of given index\n",
    "df_trun = pd.DataFrame({'Weight':[45, 88, 56, 15, 71],\n",
    "                   'Name':['Sam', 'Andrea', 'Alex', 'Robin', 'Kia'],\n",
    "                   'Age':[14, 25, 55, 8, 21]})\n",
    "index_ = pd.date_range('2010-10-09 08:45', periods = 5, freq ='H')\n",
    "df_trun.index = index_\n",
    "print(df_trun)\n",
    "print()\n",
    "print(df_trun.truncate(before = '2010-10-09 09:45:00', after = '2010-10-09 11:45:00'))\n",
    "print()\n",
    "\n",
    "series_trun = pd.Series(['New York', 'Chicago', 'Toronto', 'Lisbon', 'Rio', 'Moscow'])\n",
    "index_ = pd.date_range('2014-08-1 10:00', periods = 6, freq ='H')\n",
    "series_trun.index = index_\n",
    "print(series_trun)\n",
    "print()\n",
    "print(series_trun.truncate(before = '2014-08-1 14:00:00'))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Iterating over rows and columns in Pandas DataFrame\n",
    "dict = {'name':[\"aparna\", \"pankaj\", \"sudhir\", \"Geeku\"],\n",
    "        'degree': [\"MBA\", \"BCA\", \"M.Tech\", \"MBA\"],\n",
    "        'score':[90, 40, 80, 98]}\n",
    "df_itter = pd.DataFrame(dict)\n",
    "print(df_itter)\n",
    "print()\n",
    "\n",
    "print(\"Use of ITERROWS: \")\n",
    "for ix, val in df_itter.iterrows(): # Fetch value using iterrows\n",
    "    print(ix, \":\", val)\n",
    "print()\n",
    "\n",
    "print(\"Use of ITERTUPLES: \")\n",
    "for tup in df_itter.itertuples(): # Fetch value using itertuples\n",
    "    print(tup)\n",
    "print()\n",
    "\n",
    "df_iter = list(df_itter)\n",
    "for i in df_iter:\n",
    "    print(df_itter[i][3])\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Pandas Dataframe.sort_values() --> Sorts a data frame in Ascending or Descending order of passed Column\n",
    "data = pd.read_csv(\"Data/nba.csv\")\n",
    "print(data.head(8))\n",
    "print()\n",
    "\n",
    "data.sort_values(\"Name\", axis = 0, ascending = True, inplace = True, na_position ='last') # Sorting Frame By Name or one column, last\n",
    "print(data.head(8))\n",
    "print()\n",
    "\n",
    "data.sort_values(\"Salary\", axis = 0, ascending = True, inplace = True, na_position ='first') # Sorting Frame By Salary or one column, first\n",
    "print(data.head(8))\n",
    "print()\n",
    "\n",
    "data.sort_values([\"Team\", \"Name\"], axis=0, ascending=True, inplace=True) # Sorting Frame By two columns\n",
    "print(data.head(8))\n",
    "print()\n",
    "\n",
    "data.sort_values([\"Team\", \"Name\"], axis=0, ascending=[True,False], inplace=True) # Sorting Frame By two columns\n",
    "print(data.head(8))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Add one row in an existing Pandas DataFrame\n",
    "dict = {'Name':['Martha', 'Tim', 'Rob', 'Georgia'],\n",
    "        'Maths':[87, 91, 97, 95],\n",
    "        'Science':[83, 99, 84, 76]\n",
    "       }\n",
    "df_ar = pd.DataFrame(dict)\n",
    "print(df_ar)\n",
    "print()\n",
    "\n",
    "df_ar.loc[len(df_ar.index)] = ['Amy', 89, 93]  # Add Row\n",
    "print(df_ar)\n",
    "print()\n",
    "\n",
    "dict = {\n",
    "    'Name':['Anaya', 'Maddy'],\n",
    "    'Maths':[98, 90],\n",
    "    'Science':[39, 81]\n",
    "    } \n",
    "df_ar1 = pd.DataFrame(dict)\n",
    "df_ar = pd.concat([df_ar, df_ar1], ignore_index = True)  # Add Row\n",
    "df_ar.reset_index()\n",
    "print(df_ar)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***GROUPING***\n",
    "    -- 1. Group the unique values from the Team column.\n",
    "![Alt text](image-1.png)\n",
    "\n",
    "    -- 2. Now there’s a bucket for each group.\n",
    "![Alt text](image-2.png)\n",
    "\n",
    "    -- 3. Toss the other data into the buckets.\n",
    "![Alt text](image-3.png)\n",
    "\n",
    "    -- 4. Apply a function on the weight column of each bucket.\n",
    "![Alt text](image-4.png)\n",
    "\n",
    "    --> Group by similar values in columns\n",
    "```\n",
    "    dataframe.groupby(key)\n",
    "    dataframe.groupby(key, axis=1)\n",
    "    dataframe.groupby([key1, key2])\n",
    "```\n",
    "    --> Group by Dictionary\n",
    "```\n",
    "    dataframe.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # # GROUPING DATA\n",
    "data = {\n",
    "    'Name':['Jai', 'Anuj', 'Jai', 'Princi', 'Gaurav', 'Anuj', 'Princi', 'Abhi'],\n",
    "    'Age':[27, 24, 22, 32, 33, 36, 27, 32],\n",
    "    'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj', 'Jaunpur', 'Kanpur', 'Allahabad', 'Aligarh'],\n",
    "    'Qualification':['Msc', 'MA', 'MCA', 'Phd', 'B.Tech', 'B.com', 'Msc', 'MA'],\n",
    "    'Score': [23, 34, 35, 45, 47, 50, 52, 53]\n",
    "    }\n",
    "df_grp = pd.DataFrame(data=data)\n",
    "print(df_grp)\n",
    "print()\n",
    "\n",
    "\n",
    "# # Let's make Groups by their NAME. (By Single Key)\n",
    "print(df_grp.groupby('Name'))\n",
    "print(df_grp.groupby('Name').groups)\n",
    "print()\n",
    "\n",
    "# Let's print the first entries in all the groups formed.\n",
    "print(\"First Entry of Each Group: \\n\", df_grp.groupby('Name').first())\n",
    "print()\n",
    "\n",
    "# Let's print the last entries in all the groups formed.\n",
    "print(\"Last Entry of Each Group: \\n\", df_grp.groupby('Name').last())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# # Using multiple keys in groupby() function\n",
    "print(df_grp.groupby(['Name', 'Qualification']))\n",
    "print(df_grp.groupby(['Name', 'Qualification']).groups)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Grouping Dataframe with sort and without sort:\n",
    "data = {\n",
    "    'Name':['Jai', 'Anuj', 'Jai', 'Princi', 'Gaurav', 'Anuj', 'Princi', 'Abhi'],\n",
    "    'Age':[27, 24, 22, 32, 33, 36, 27, 32]\n",
    "    }\n",
    "df_grp1 = pd.DataFrame(data=data)\n",
    "print(df_grp1)\n",
    "print()\n",
    "\n",
    "# With sort (by default sort is True)\n",
    "print(\"Without Sort: \\n\", df_grp1.groupby(['Name']).sum())\n",
    "\n",
    "# With sort (by default sort is True)\n",
    "print(\"With Sort: \\n\", df_grp1.groupby(['Name'], sort=False).sum())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Iteration Groups:\n",
    "# Single key value iteration\n",
    "grp = df_grp.groupby(\"Name\")\n",
    "for name, group in grp:\n",
    "    print(name, \"\\n\", group)\n",
    "print()\n",
    "\n",
    "print(grp.get_group('Jai'))\n",
    "print()\n",
    "\n",
    "# Multiple key value iteration\n",
    "grp1 = df_grp.groupby([\"Name\", \"Qualification\"])\n",
    "for name, group in grp:\n",
    "    print(name, \"\\n\", group)\n",
    "print()\n",
    "\n",
    "print(grp.get_group((\"Jai\", \"Msc\")))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Apply Aggregate function to the groups\n",
    "print(\"SUM: \", grp.aggregate(np.sum)) # Sum of all the groups value. (By Single function)\n",
    "print()\n",
    "print(\"SUM :\", grp1.aggregate(np.sum)) # Sum of all the groups value. (By Single function)\n",
    "print()\n",
    "print(\"Multiple Function at once: \\n\", grp[\"Age\"].agg([np.sum, np.mean, np.std])) # Apply multiple function simultaneously.\n",
    "print()\n",
    "print(\"Multiple Function at once: \\n\", grp1[\"Age\"].agg([np.sum, np.mean, np.std])) # Apply multiple function simultaneously.\n",
    "print()\n",
    "\n",
    "# Applying different functions to DataFrame columns\n",
    "print(\"Apply function in another way: \\n\", grp.agg({'Age' : 'sum', 'Score' : 'std'}))\n",
    "print()\n",
    "# Using transform, filter function\n",
    "print(\"BY TRANSFORM: \\n\", grp['Age'].transform(lambda x: (x - x.mean()) / x.std()*10))\n",
    "print()\n",
    "print(\"BY FILTER: \\n\", grp['Age'].filter(lambda x: len(x) >= 2))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Grouping by Rows in DataFrame\n",
    "data = {\n",
    "    'Team':[\n",
    "        'Australia', 'England', 'South Africa','Australia', 'England',\n",
    "        'India', 'India', 'South Africa', 'England', 'India'\n",
    "        ],\n",
    "    'Player':[\n",
    "        'Ricky Ponting', 'Joe Root', 'Hashim Amla', 'David Warner', 'Jos Buttler', 'Virat Kohli',\n",
    "        'Rohit Sharma', 'David Miller', 'Eoin Morgan','Dinesh Karthik'\n",
    "        ],\n",
    "    'Runs':[345, 336, 689, 490, 989, 672, 560, 455, 342, 376],\n",
    "    'Salary':[34500, 33600, 68900, 49000, 98899, 67562, 56760, 45675, 34542, 31176]\n",
    "    }\n",
    "df_grp = pd.DataFrame(data)\n",
    "print(df_grp.head(5))\n",
    "print()\n",
    "\n",
    "print(df_grp['Salary'].groupby(df_grp[\"Team\"]))\n",
    "print(df_grp['Salary'].groupby(df_grp[\"Team\"]).groups)\n",
    "print()\n",
    "\n",
    "print(\"Print Fist Data of the Groups: \\n\", df_grp['Salary'].groupby(df_grp[\"Team\"]).first()) # Print first elements or data of groups\n",
    "print()\n",
    "\n",
    "print(\"Print Last Data of the Groups: \\n\", df_grp['Salary'].groupby(df_grp[\"Team\"]).last()) # Print last data of groups\n",
    "print()\n",
    "\n",
    "# Print means of the groups or we apply many function to it same as above\n",
    "print(\"Means of the Salary: \\n\", df_grp['Salary'].groupby(df_grp[\"Team\"]).mean())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Combining multiple columns in Pandas groupby with dictionary\n",
    "data = {\n",
    "    'id':['1', '2', '3'],\n",
    "    'Column 1.1':[14, 15, 16],\n",
    "    'Column 1.2':[10, 10, 10],\n",
    "    'Column 1.3':[1, 4, 5],\n",
    "    'Column 2.1':[1, 2, 3],\n",
    "    'Column 2.2':[10, 10, 10]\n",
    "    }\n",
    "df_grp = pd.DataFrame(data=data)\n",
    "df_grp = df_grp.set_index('id')\n",
    "\n",
    "# Creating the groupby dictionary \n",
    "groupby_dict = {\n",
    "    'Column 1.1':'Column 1',\n",
    "    'Column 1.2':'Column 1',\n",
    "    'Column 1.3':'Column 1',\n",
    "    'Column 2.1':'Column 2',\n",
    "    'Column 2.2':'Column 2'\n",
    "    }\n",
    "\n",
    "# Groupby the groupby_dict created above with axis and without axis\n",
    "grp = df_grp.groupby(groupby_dict)\n",
    "print(grp)\n",
    "print(grp.groups)\n",
    "print()\n",
    "print(\"Print first data of the groups: \\n\", grp.first())\n",
    "print()\n",
    "print(\"Print last data of the groups: \\n\", grp.last())\n",
    "\n",
    "grp = df_grp.groupby(groupby_dict, axis = 1)\n",
    "print(grp)\n",
    "print(grp.groups)\n",
    "print()\n",
    "\n",
    "print(\"Print first data of the groups: \\n\", grp.first())\n",
    "print()\n",
    "print(\"Print last data of the groups: \\n\", grp.last())\n",
    "print()\n",
    "\n",
    "# with function operation\n",
    "data = {\n",
    "    \"ID\":[1, 2, 3],\n",
    "    \"Movies\":[\"The Godfather\", \"Fight Club\", \"Casablanca\"],\n",
    "    \"Week_1_Viewers\":[30, 30, 40],\n",
    "    \"Week_2_Viewers\":[60, 40, 80],\n",
    "    \"Week_3_Viewers\":[40, 20, 20]\n",
    "    }\n",
    "df_grp = pd.DataFrame(data=data)\n",
    "df_grp = df_grp.set_index('ID')\n",
    "print(df_grp)\n",
    "print()\n",
    "\n",
    "# Creating the groupby dictionary\n",
    "groupby_dict = {\n",
    "    \"Week_1_Viewers\":\"Total_Viewers\",\n",
    "    \"Week_2_Viewers\":\"Total_Viewers\",\n",
    "    \"Week_3_Viewers\":\"Total_Viewers\",\n",
    "    \"Movies\":\"Movies\"\n",
    "    }\n",
    "grp = df_grp.groupby(groupby_dict, axis=1)\n",
    "print(grp)\n",
    "print(grp.groups)\n",
    "print()\n",
    "print(\"Print first data of the groups: \\n\", grp.first())\n",
    "print()\n",
    "print(\"Print last data of the groups: \\n\", grp.last())\n",
    "print()\n",
    "print(\"Summation of all the group data: \\n\", grp.sum())\n",
    "print()\n",
    "print(\"Minimum value of the grouped data: \\n\", grp.min())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***MERGING, JOINING, CONCATING, and COMPARING***\n",
    "    -- Merging dataframe using `how` in an argument:\n",
    "![Alt text](image-5.png)\n",
    "\n",
    "\n",
    "    --> Concating dataframe and series by using JOIN\n",
    "```\n",
    "    dataframe.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False, validate=None)\n",
    "```\n",
    "    --> Concating dataframe and series by using MERGE\n",
    "```\n",
    "    dataframe.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None)\n",
    "```\n",
    "    --> Concating dataframe and series by using CONCAT\n",
    "```\n",
    "    pd.concat(objs, *, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=None)\n",
    "```\n",
    "    --> Concating dataframe and series by using CAT\n",
    "```\n",
    "    series.str.cat(others=None, sep=None, na_rep=None)\n",
    "```\n",
    "    --> Concating dataframe and series by using APPEND\n",
    "```\n",
    "    dataframe.append(other, ignore_index=False, verify_integrity=False, sort=None)  \n",
    "    series.append(other, ignore_index=False, verify_integrity=False, sort=None)  \n",
    "    index.append(other, ignore_index=False, verify_integrity=False, sort=None)  \n",
    "```\n",
    "    --> Concating dataframe and series by using COMBINE\n",
    "```\n",
    "    series.combine(other, func, fill_value=nan)\n",
    "```\n",
    "    --> Concating dataframe and series by using str.join\n",
    "```\n",
    "    series.str.join(sep)\n",
    "```\n",
    "    --> Comparing dataframe and series by using COMPARE\n",
    "```\n",
    "    dataframe.compare(other, align_axis=1, keep_shape=False, keep_equal=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # # MERGING, JOINING, CONCATINATING and COMPARING.\n",
    "# dataFrame one\n",
    "data_1 = {\n",
    "    'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "    'Age':[27, 24, 22, 32],\n",
    "    'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
    "    'Qualification':['Msc', 'MA', 'MCA', 'Phd']\n",
    "    }\n",
    "\n",
    "data_2 = {\n",
    "    'Name':['Abhi', 'Ayushi', 'Dhiraj', 'Hitesh'],\n",
    "    'Age':[17, 14, 12, 52],\n",
    "    'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
    "    'Qualification':['Btech', 'B.A', 'Bcom', 'B.hons']\n",
    "    }\n",
    "df_c1 = pd.DataFrame(data_1)\n",
    "df_c2 = pd.DataFrame(data_2)\n",
    "\n",
    "# dataFrame two\n",
    "data_3 = {\n",
    "    'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'], \n",
    "    'Age':[27, 24, 22, 32], \n",
    "    'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'], \n",
    "    'Qualification':['Msc', 'MA', 'MCA', 'Phd'],\n",
    "    'Mobile No': [97, 91, 58, 76]\n",
    "    }\n",
    "\n",
    "data_4 = {\n",
    "    'Name':['Gaurav', 'Anuj', 'Dhiraj', 'Hitesh'], \n",
    "    'Age':[22, 32, 12, 52], \n",
    "    'Address':['Allahabad', 'Kannuaj', 'Allahabad', 'Kannuaj'], \n",
    "    'Qualification':['MCA', 'Phd', 'Bcom', 'B.hons'],\n",
    "    'Salary':[1000, 2000, 3000, 4000]\n",
    "    }\n",
    "df_c3 = pd.DataFrame(data_3).set_index('Name')\n",
    "df_c4 = pd.DataFrame(data_4).set_index('Name')\n",
    "print(df_c1, \"\\n\\n\", df_c2)\n",
    "print()\n",
    "print(\"Concatenation of two Dataframe: \\n\", pd.concat([df_c1, df_c2], ignore_index=True))\n",
    "print()\n",
    "\n",
    "# # Concatenation of two Dataframe using Join\n",
    "print(df_c3, \"\\n\\n\", df_c4)\n",
    "print()\n",
    "print(\"Concatenation of two Dataframe using Join: \\n\", pd.concat([df_c3, df_c4], axis=1, join='inner'))\n",
    "print()\n",
    "\n",
    "print(pd.concat([df_c3, df_c4], axis=1, sort=False)) # using a .concat for union of dataframe\n",
    "print()\n",
    "print(pd.concat([df_c1, df_c2], keys=['x', 'y']))\n",
    "print()\n",
    "\n",
    "# Concatenating with mixed ndims\n",
    "series_c = pd.Series([1000, 2000, 3000, 4000], name='Salary')\n",
    "print(pd.concat([df_c1, series_c], axis=1))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Merging DataFrame abd Joining (by merge and join)\n",
    "data_1 = {\n",
    "    'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "    'key1': ['K0', 'K0', 'K2', 'K5'],\n",
    "    'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "    'Age':[27, 24, 22, 32]\n",
    "    }\n",
    "\n",
    "data_2 = {\n",
    "    'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "    'key1': ['K1', 'K1', 'K2', 'K4'],\n",
    "    'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
    "    'Qualification':['Btech', 'B.A', 'Bcom', 'B.hons']\n",
    "    }\n",
    "df_c1 = pd.DataFrame(data_1)\n",
    "df_c2 = pd.DataFrame(data_2)\n",
    "\n",
    "print(df_c1, \"\\n\\n\", df_c2)\n",
    "print()\n",
    "print(pd.merge(df_c1, df_c2, on='key'))\n",
    "print()\n",
    "print(pd.merge(df_c1, df_c2, how='left', on=['key', 'key1']))\n",
    "print()\n",
    "print(pd.merge(df_c1, df_c2, how='right', on=['key', 'key1']))\n",
    "print()\n",
    "print(pd.merge(df_c1, df_c2, how='outer', on=['key1', 'key1']))\n",
    "print()\n",
    "print(pd.merge(df_c1, df_c2, how='inner', on=['key', 'key1']))\n",
    "print()\n",
    "df_c1 = df_c1.set_index('key1')\n",
    "df_c2 = df_c2.set_index('key')\n",
    "print(df_c1.join(df_c2))\n",
    "print()\n",
    "print(df_c1.join(df_c2, on='key'))\n",
    "print()\n",
    "print(df_c1.join(df_c2, on='key', how=\"left\"))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Pandas Series.str.cat() to concatenate string\n",
    "df_cat = pd.read_csv(\"Data/nba.csv\")\n",
    "print(df_cat.head())\n",
    "print()\n",
    "\n",
    "# concatenating team with name column overwriting name column\n",
    "df_cat1 = df_cat[\"Team\"].copy()\n",
    "df_cat[\"Name\"]= df_cat[\"Name\"].str.cat(df_cat1, sep =\", \")\n",
    "print(df_cat.head())\n",
    "print()\n",
    "\n",
    "df_cat1 = df_cat[\"Team\"].copy()\n",
    "na_string = \"No College\"\n",
    "df_cat[\"College\"]= df_cat[\"College\"].str.cat(df_cat1, sep =\", \", na_rep = na_string)\n",
    "print(df_cat.head())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Merging data with using Pandas index.append()\n",
    "ix_app = pd.Index(['New York', 'Chicago', 'Toronto', 'Lisbon', 'Rio'])\n",
    "ix_app_1 = pd.Index(['Chicage', 'Shanghai', 'Beijing', 'Jakarta', 'Seoul'])\n",
    "print(ix_app, \"\\n\", ix_app_1)\n",
    "print()\n",
    "print(ix_app.append(ix_app_1))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Pandas Series.combine()\n",
    "sr_com = pd.Series([1, 2, 5, 6, 3, 7, 11, 0, 4])\n",
    "sr_com_1 = pd.Series([5, 3, 2, 1, 3, 9, 21, 3, 1])\n",
    "print(sr_com, \"\\n\", sr_com_1)\n",
    "print()\n",
    "print(sr_com.combine(sr_com_1, (lambda x1, x2: x1 if x1 < x2 else x2))) # without NULL Values\n",
    "print()\n",
    "\n",
    "sr_com = pd.Series([1, 2, np.nan, 5, 6, 3, np.nan, 7, 11, 0, 4, 8])\n",
    "sr_com_1 = pd.Series([5, 3, 2, np.nan, 1, 3, 9, 21, 3, np.nan, 1, np.nan])\n",
    "print(sr_com, \"\\n\", sr_com_1)\n",
    "print(sr_com.combine(sr_com_1, func=(lambda x1, x2: x1 if x1 > x2 else x2), fill_value=5)) # with NULL Values\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # Add a row at top in pandas DataFrame\n",
    "data = pd.read_csv(\"Data/nba.csv\")\n",
    "print(data.head())\n",
    "print()\n",
    "\n",
    "add_row = pd.DataFrame({\n",
    "    'Name':'Geeks', 'Team':'Boston', 'Number':3, 'Position':'PG', 'Age':33, 'Height':'6-2', \n",
    "    'Weight':189, 'College':'MIT', 'Salary':99999}, index =[0]\n",
    "    )\n",
    "print((pd.concat([add_row, data]).reset_index(drop=True)).head(5))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Pandas str.join() to join string/list elements with passed delimiter\n",
    "data.dropna(inplace = True) # Drop the Null value columns\n",
    "data[\"Name\"]= data[\"Name\"].str.join(\"-\")\n",
    "print(data.head(5))\n",
    "print()\n",
    "\n",
    "data[\"Team\"]= data[\"Team\"].str.split(\"t\")\n",
    "data[\"Team\"]= data[\"Team\"].str.join(\"_\")\n",
    "print(data.head(5))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Join two text columns into a single column in Pandas\n",
    "df_scj = pd.DataFrame({\n",
    "    'Last': ['Gaitonde', 'Singh', 'Mathur'],\n",
    "    'First': ['Ganesh', 'Sartaj', 'Anjali']\n",
    "    })\n",
    "print(df_scj)\n",
    "print()\n",
    "\n",
    "# Below three are return same values\n",
    "df_scj['Name'] = df_scj['First'].str.cat(df_scj['Last'], sep =\" \")\n",
    "df_scj['Name'] = df_scj[['First', 'Last']].apply(lambda x: ' '.join(x), axis = 1)\n",
    "df_scj['Name'] = df_scj[\"First\"].astype(str) +\" \"+ df_scj[\"Last\"]\n",
    "print(df_scj)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Compare Two Dataframes with Pandas compare\n",
    "df_cmp_1 = pd.DataFrame({\n",
    "    \"Stationary\": [\"Pens\", \"Scales\", \"Pencils\", \"Geometry Box\", \"Crayon Set\"],\n",
    "    \"Price\": [100, 50, 25, 100, 65],\n",
    "    \"Quantity\": [10, 5, 5, 2, 1]\n",
    "    },columns=[\"Stationary\", \"Price\", \"Quantity\"])\n",
    "\n",
    "df_cmp_2 = df_cmp_1.copy()\n",
    "df_cmp_2.loc[0, 'Price'] = 150 \n",
    "df_cmp_2.loc[1, 'Price'] = 70\n",
    "df_cmp_2.loc[2, 'Price'] = 30\n",
    "df_cmp_2.loc[0, 'Quantity'] = 15\n",
    "df_cmp_2.loc[1, 'Quantity'] = 7\n",
    "df_cmp_2.loc[2, 'Quantity'] = 6\n",
    "\n",
    "print(df_cmp_1, \"\\n\\n\", df_cmp_2)\n",
    "print()\n",
    "print(\"DataFrame Compare without Parameter: \\n\", df_cmp_1.compare(df_cmp_2))\n",
    "print()\n",
    "print(\"DataFrame Compare with Parameter - align_axis: \\n\", df_cmp_1.compare(df_cmp_2, align_axis=0))\n",
    "print()\n",
    "print(\"DataFrame Compare with Parameter - keep_equal: \\n\", df_cmp_1.compare(df_cmp_2, keep_equal=True))\n",
    "print()\n",
    "print(\"DataFrame Compare with Parameter - keep_equal: \\n\", df_cmp_1.compare(df_cmp_2, keep_equal=False))\n",
    "print()\n",
    "print(\"DataFrame Compare with Parameter - keep_shape: \\n\", df_cmp_1.compare(df_cmp_2, keep_shape=True))\n",
    "print()\n",
    "print(\"DataFrame Compare with Parameter - keep_shape & keep_equal: \\n\", df_cmp_1.compare(df_cmp_2, keep_shape=True, keep_equal=True))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # compare the elements of the two Pandas Series\n",
    "sr_cmp_1 = pd.Series([2.5, 4, 6, 8, 10, 1.75, 40])\n",
    "sr_cmp_2 = pd.Series([1.5, 3, 5, 7, 10, 1.75, 20])\n",
    "print(\"Series: \", sr_cmp_1)\n",
    "print(\"Series: \", sr_cmp_2)\n",
    "print()\n",
    "\n",
    "print(\"Compare with '==': \\n\", sr_cmp_1 == sr_cmp_2, \"\\n\")\n",
    "print(\"Compare with '!=': \\n\", sr_cmp_1 != sr_cmp_2, \"\\n\")\n",
    "print(\"Compare with '>': \\n\", sr_cmp_1 < sr_cmp_2, \"\\n\")\n",
    "print(\"Compare with '<': \\n\", sr_cmp_1 > sr_cmp_2, \"\\n\")\n",
    "\n",
    "print(\"Comparing two DataFrame with using .equals: \", df_cmp_1.equals(df_cmp_2))\n",
    "print(\"Comparing two DataFrame with using .equals: \", df_cmp_1.equals(df_cmp_1))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***WORKING WITH DATE AND TIME***\n",
    "    --> Create Dataframe or list of Dates using date_range\n",
    "```\n",
    "    pandas.date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, **kwargs)\n",
    "```\n",
    "    --> Display current time using datetime.now() function\n",
    "```\n",
    "    pd.Timestamp.now()\n",
    "    pd.datetime.now()\n",
    "```\n",
    "    --> Fetch particular value like [month, year, day, hour, minute, second]\n",
    "```\n",
    "    pandas.Series.dt.year\n",
    "    pandas.Series.dt.month\n",
    "    pandas.Series.dt.day\n",
    "    pandas.Series.dt.hour\n",
    "    pandas.Series.dt.minute\n",
    "```\n",
    "    --> Set Timestamp and working ewith them also it has sub function [.now(), .timestamp(), .isoformat(), .date(), .replace()]\n",
    "```\n",
    "    pandas.Timestamp(ts_input=<object object>, year=None, month=None, day=None, hour=None, minute=None, second=None, microsecond=None, tzinfo=None, *, nanosecond=None, tz=None, unit=None, fold=None)\n",
    "\n",
    "    pandas.Timestamp.now(tz=None)\n",
    "\n",
    "    pandas.Timestamp.isoformat(sep, timespec)\n",
    "\n",
    "    pandas.Timestamp.replace(year=None, month=None, day=None, hour=None, minute=None, second=None, microsecond=None, nanosecond=None, tzinfo=<class 'object'>, fold=None)\n",
    "```\n",
    "    --> Change value to date and time format\n",
    "```\n",
    "    pandas.to_datetime(arg, errors=’raise’, dayfirst=False, yearfirst=False, utc=None, box=True, format=None, exact=True, unit=None, infer_datetime_format=False, origin=’unix’, cache=False)  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # # WORKING WITH DATE AND TIME\n",
    "# # Create dates data\n",
    "dates = pd.date_range('1/1/2011', periods = 15, freq ='H') # create 10 data for duration 1 hour\n",
    "print(dates)\n",
    "print()\n",
    "\n",
    "print(\"Days: \", dates.day, \"\\n\")\n",
    "print(\"Months: \", dates.month, \"\\n\")\n",
    "print(\"Years: \", dates.year, \"\\n\")\n",
    "print(\"Hours: \", dates.hour, \"\\n\")\n",
    "print(\"Minutes: \", dates.minute, \"\\n\")\n",
    "\n",
    "print(pd.Timestamp.now()) # Print Present time\n",
    "print(\"Days: \", (pd.Timestamp.now()).day)\n",
    "print(\"Months: \", (pd.Timestamp.now()).month)\n",
    "print(\"Years: \", (pd.Timestamp.now()).year)\n",
    "print(\"Hours: \", (pd.Timestamp.now()).hour)\n",
    "print(\"Minutes: \", (pd.Timestamp.now()).minute)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Analyze this problem on a real dataset uforeports.\n",
    "df_dts = pd.read_csv('Data/ufo.csv')\n",
    "print(df_dts.head())\n",
    "print()\n",
    "\n",
    "df_dts['Time'] = pd.to_datetime(df_dts.Time)\n",
    "print(df_dts.head())\n",
    "print()\n",
    "print(\"Datatypes of Each Columns: \\n\", df_dts.dtypes)\n",
    "print()\n",
    "print(\"Hour from Date data: \\n\", df_dts.Time.dt.hour.head())\n",
    "print()\n",
    "print(\"Name of Day from Date data: \\n\", df_dts.Time.dt.day_name().head())\n",
    "print()\n",
    "print(\"Ordinal day of year from Date data: \\n\", df_dts.Time.dt.dayofyear.head())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Pandas Timestamp.timestamp\n",
    "data_ts = pd.Timestamp(year = 2011,  month = 11, day = 21, hour = 10, second = 49, tz = 'Asia/Kolkata')\n",
    "print(\"Time Stamp: \", data_ts)\n",
    "print()\n",
    "\n",
    "print(\"Number of Hours: \", data_ts.timestamp())\n",
    "print()\n",
    "print(\"Time Structure: \", data_ts.timetuple())\n",
    "print()\n",
    "print(\"Time: \", data_ts.timetz())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Create data and working with them by timestamp.now(), timestamp.isoformat(), timestamp.now()\n",
    "print(\"Current Timestamp: \", pd.Timestamp.now())\n",
    "print()\n",
    "\n",
    "data_ts_1 = pd.date_range(end=pd.Timestamp.now(), periods=5, freq='D')\n",
    "print(\"Date range Until till: \\n\", data_ts_1)\n",
    "print()\n",
    "\n",
    "df_ts = pd.DataFrame({\"Time Stamps\":data_ts_1, \"Temperature\": [21.2, 23.2, 27.2, 29.2, 31.2]})\n",
    "print(\"Make it DataFrame: \\n\", df_ts)\n",
    "print()\n",
    "\n",
    "print(\"ISO Formate: \", (pd.Timestamp.now()).isoformat())\n",
    "print(\"Today's Date: \", (pd.Timestamp.now()).date())\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Create data and working with them by timestamp.replace(), to_datetime(), date_range()\n",
    "print(\"Today's Date Before Replace: \", (pd.Timestamp.now()))\n",
    "print(\"Today's Date After Replace: \", (pd.Timestamp.now()).replace(year=2024))\n",
    "print()\n",
    "print(\"Today's Date Before Replace: \", (pd.Timestamp.now()))\n",
    "print(\"Today's Date After Replcae: \", (pd.Timestamp.now()).replace(year=2012, month=12, day=12, \n",
    "                                                                   hour=12, minute=12, second=12, microsecond=12))\n",
    "print()\n",
    "\n",
    "# Working with datasets\n",
    "data = pd.read_csv('Data/todatetime.csv')\n",
    "print(\"Before apply operation: \\n\", data)\n",
    "print(\"Information about data: \\n\", data.info())\n",
    "print()\n",
    "\n",
    "data[\"Time\"]= pd.to_datetime(data[\"Time\"])\n",
    "print(\"After apply operation: \\n\", data)\n",
    "print(\"Information about data: \\n\", data.info())\n",
    "print()\n",
    "\n",
    "dt_rng  = pd.date_range(start=\"1/1/2018\", end=\"1/08/2018\", freq='1D')\n",
    "print(\"Date Ranges: \\n\", dt_rng)\n",
    "print()\n",
    "\n",
    "dt_rng  = pd.date_range(start=\"1/1/2018\", periods=10, freq='1D')\n",
    "print(\"Date Ranges: \\n\", dt_rng)\n",
    "print()\n",
    "\n",
    "dt_rng  = pd.date_range(start ='01-03-2017',  end ='1-1-2018', periods = 10, tz='Asia/Kolkata')\n",
    "print(\"Date Ranges: \\n\", dt_rng)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***WORKING WITH TEXT DATA***\n",
    "    --> Change the cases of text data from dataframe\n",
    "```\n",
    "    dataframe['column'].str.lower()\n",
    "    dataframe['column'].str.upper()\n",
    "    dataframe['column'].str.title()\n",
    "```\n",
    "    --> Split text data and concatenating text data\n",
    "```\n",
    "    dataframe.str.cat(other, sep)\n",
    "    dataframe['column'].str.split(sep,  expand, n)\n",
    "\n",
    "    series.str.cat(other, sep)\n",
    "    series.str.split(sep,  expand, n)\n",
    "```\n",
    "    --> Replace data from text values\n",
    "```\n",
    "    dataframe.replace(to_replace=None, value=_NoDefault.no_default, *, inplace=False, limit=None, regex=False, method=_NoDefault.no_default)\n",
    "```\n",
    "    --> Removing Whitespace from text data\n",
    "```\n",
    "    series.str.lstrip(to_strip=None)\n",
    "    series.str.rstrip(to_strip=None)\n",
    "    series.str.strip(to_strip=None)\n",
    "```\n",
    "    --> Increment dateoffset to date\n",
    "```\n",
    "    pandas.tseries.offsets.DateOffset(n=1, normalize=False, **kwds)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # #  WORKING WITH TEXT DATA\n",
    "data = {\n",
    "    'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "    'Age':[27, 24, 22, 32],\n",
    "    'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Knnuaj'],\n",
    "    'Qualification':['Msc', 'MA', 'MCA', 'Phd']\n",
    "}\n",
    "df_txt = pd.DataFrame(data)\n",
    "print(df_txt)\n",
    "print()\n",
    "\n",
    "data = pd.read_csv(\"Data/nba.csv\")\n",
    "print(data.head())\n",
    "print()\n",
    "\n",
    "# df_txt[\"Address\"]= df_txt[\"Address\"].str.split(\"a\", n=1, expand=True)\n",
    "df_txt[\"Address\"]= df_txt[\"Address\"].apply(lambda x: x.split('A', 1)[0] if 'A' in x else x)\n",
    "print(\"After applying split: \\n\", df_txt)\n",
    "print()\n",
    "\n",
    "df_txt['Name'] = df_txt['Name'].str.cat(df_txt['Qualification'], sep=\" , \") # concatenating two string {Series}\n",
    "print(\"After applying Operation: \\n\", df_txt)\n",
    "print()\n",
    "\n",
    "sr_txt = pd.Series(['a1', 'b2', 'c3'])\n",
    "print(\"Extract: \\n\", sr_txt.str.extract(r'([ab])(\\d)'))\n",
    "print()\n",
    "\n",
    "sr_txt = pd.Series(['a1', 'b2', 'c3'])\n",
    "print(\"Extract: \\n\", sr_txt.str.extract(r'(?P<Letter>[ab])(?P<Digit>\\d)'))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Using lower, upper, title function\n",
    "df_txt[\"Name\"]= df_txt[\"Name\"].str.lower()\n",
    "print(\"After applying lower function: \\n\", df_txt)\n",
    "print()\n",
    "\n",
    "df_txt[\"Address\"]= df_txt[\"Address\"].str.upper()\n",
    "print(\"After applying upper function: \\n\", df_txt)\n",
    "print()\n",
    "\n",
    "df_txt[\"Address\"]= df_txt[\"Address\"].str.upper().str.title()\n",
    "print(\"After applying title function: \\n\", df_txt)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Replacing dataframe and series\n",
    "data[\"Age\"]= data[\"Age\"].replace(25.0, \"Twenty five\") # replace value by replace function\n",
    "filter = data[\"Age\"]==\"Twenty five\" # creating a filter for age column  where age = \"Twenty five\"\n",
    "print(\"Filter data: \\n\", (data.where(filter).dropna()).head())\n",
    "print()\n",
    "\n",
    "sr_txt = pd.Series([10, 25, 3, 11, 24, 6])\n",
    "index_ = ['Coca Cola', 'Sprite', 'Coke', 'Fanta', 'Dew', 'ThumbsUp']\n",
    "sr_txt.index = index_\n",
    "print(\"Series: \\n\", sr_txt)\n",
    "print()\n",
    "\n",
    "sr_txt = sr_txt.replace(to_replace = 3, value = 1000)\n",
    "print(\"Update Series: \\n\", sr_txt)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Using strip to remove whitespace\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "data[\"Team\"] = data[\"Team\"].replace(\"Boston Celtics\", \" Boston Celtics \") # applying lstrip\n",
    "print(data['Team'].str.lstrip()==\"Boston Celtics \")\n",
    "print()\n",
    "\n",
    "data[\"Team\"] = data[\"Team\"].replace(\"Boston Celtics\", \" Boston Celtics \") # applying lstrip\n",
    "print(data['Team'].str.rstrip()==\" Boston Celtics\")\n",
    "print()\n",
    "\n",
    "data[\"Team\"] = data[\"Team\"].replace(\"Boston Celtics\", \" Boston Celtics \") # applying strip\n",
    "print(data['Team'].str.strip()==\" Boston Celtic\", \"\\n\")\n",
    "print(data['Team'].str.strip()==\"Boston Celtics \", \"\\n\")\n",
    "print(data['Team'].str.strip()==\" Boston Celtic \")\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Timestamp\n",
    "ts_txt = pd.Timestamp('2019-10-10 07:15:11')\n",
    "print(ts_txt)\n",
    "print()\n",
    "\n",
    "print(\"Set dateOffset:  \", pd.tseries.offsets.DateOffset(n = 2))\n",
    "print()\n",
    "print(\"After applying dateOffset:  \", (ts_txt + pd.tseries.offsets.DateOffset(n = 2)))\n",
    "print()\n",
    "\n",
    "print(\"Set in hour dateOffset:  \", pd.tseries.offsets.DateOffset(days = 10, hours = 2))\n",
    "print()\n",
    "print(\"After applying dateOffset:  \", (ts_txt + pd.tseries.offsets.DateOffset(days = 10, hours = 2)))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***WORKING WITH CSV AND EXCEL FILES***\n",
    "    --> Read csv files and load to dataframe and save dataframe to csv\n",
    "```\n",
    "    pandas.read_csv(filepath_or_buffer, *, sep=_NoDefault.no_default, delimiter=None, header='infer', names=_NoDefault.no_default, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=None, infer_datetime_format=_NoDefault.no_default, keep_date_col=False, date_parser=_NoDefault.no_default, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, on_bad_lines='error', delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=_NoDefault.no_default)\n",
    "\n",
    "    DataFrame.to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors='strict', storage_options=None)\n",
    "```\n",
    "\n",
    "    --> Read Excel files and save to Excel file\n",
    "```\n",
    "    pandas.read_excel(io, sheet_name=0, *, header=0, names=None, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, parse_dates=False, date_parser=_NoDefault.no_default, date_format=None, thousands=None, decimal='.', comment=None, skipfooter=0, storage_options=None, dtype_backend=_NoDefault.no_default, engine_kwargs=None)\n",
    "\n",
    "    pandas.ExcelFile(path_or_buffer, engine=None, storage_options=None, engine_kwargs=None)\n",
    "\n",
    "    dataframe.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None, engine_kwargs=None)\n",
    "```\n",
    "\n",
    "    --> Lets create excel writer and their function\n",
    "```\n",
    "    pandas.ExcelWriter(path, engine=None, date_format=None, datetime_format=None, mode='w', storage_options=None, if_sheet_exists=None, engine_kwargs=None)\n",
    "\n",
    "    xlsxwriter.Workbook(file, **engine_kwargs)\n",
    "    openpyxl.Workbook(**engine_kwargs)  # Write mode\n",
    "    openpyxl.load_workbook(file, **engine_kwargs)  # append mode\n",
    "\n",
    "    format = workbook.add_format(properties)\n",
    "    sheet.insert_image(row, col, image_path, options)\n",
    "    sheet.set_row(row, height, cell_format, options)\n",
    "    sheet.set_column(first_col, last_col, width)\n",
    "    sheet.write(row, col, value)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # # WORKING WITH CSV AND EXCEL FILES\n",
    "Data = pd.read_csv(\"Data/employees.csv\")\n",
    "print(Data.head(8))\n",
    "print()\n",
    "\n",
    "Data = pd.read_csv(\"Data/employees.csv\", sep='[:, |_]', engine='python')\n",
    "print(Data.head(8))\n",
    "print()\n",
    "\n",
    "Data = pd.read_csv(\"Data/employees.csv\", header=0, usecols=[\"First Name\", \"Gender\", \"Last Login Time\"])\n",
    "print(Data.head(8))\n",
    "print()\n",
    "\n",
    "Data = pd.read_csv(\"Data/employees.csv\", header=0, index_col=[\"Gender\", \"Team\"], usecols=[\"Gender\", \"Team\", \"Last Login Time\"])\n",
    "print(Data.head(8))\n",
    "print()\n",
    "\n",
    "Data = pd.read_csv(\"Data/employees.csv\", skiprows = [1,5])\n",
    "print(Data.head(8))\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Saving DataFrame as csv\n",
    "# Create DataFrame\n",
    "df_csv = pd.DataFrame({\n",
    "    'Name': [\"aparna\", \"pankaj\", \"sudhir\", \"Geeku\"],\n",
    "    'Degree': [\"MBA\", \"BCA\", \"M.Tech\", \"MBA\"],\n",
    "    'Score': [90, 40, 80, 98]\n",
    "})\n",
    "print(df_csv)\n",
    "print()\n",
    "\n",
    "# saving the dataframe\n",
    "df.to_csv('Data/file.csv')\n",
    "df.to_csv('Data/file.csv', header=False, index=False)\n",
    "df.to_csv('Data/Users.csv', sep='\\t', index=False,header=True)\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "\n",
    "# # Load Excel Spreadsheets\n",
    "data_exl = pd.ExcelFile('Data/Test.xlsx')\n",
    "print(\"Names of sheet in file:  \", data_exl.sheet_names)\n",
    "print(\"Printing Sheet1 data:  \\n\", data_exl.parse('Sheet1'))\n",
    "print()\n",
    "\n",
    "data_exl = pd.read_excel('Data/Test.xlsx', usecols = [1, 3])\n",
    "print(\"Printing Sheet1 data:  \\n\", data_exl)\n",
    "print()\n",
    "\n",
    "data_exl = pd.read_excel('Data/Test.xlsx', header=2)\n",
    "print(\"Printing Sheet1 data:  \\n\", data_exl)\n",
    "print()\n",
    "\n",
    "data_exl = pd.read_excel('Data/Test.xlsx', skiprows=2)\n",
    "print(\"Printing Sheet1 data:  \\n\", data_exl)\n",
    "print()\n",
    "\n",
    "data_exl = pd.read_excel('Data/Test.xlsx', na_values=\"Missing\")\n",
    "print(\"Printing Sheet1 data:  \\n\", data_exl)\n",
    "print()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# # Working with XLSXWRITER\n",
    "df_exl = pd.DataFrame({\n",
    "    'Name': [\"aparna\", \"pankaj\", \"sudhir\", \"Geeku\"],\n",
    "    'Degree': [\"MBA\", \"BCA\", \"M.Tech\", \"MBA\"],\n",
    "    'Score': [90, 40, 80, 98]\n",
    "})\n",
    "# Create a Pandas Excel writer object using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('Data/file.xlsx', engine ='xlsxwriter')\n",
    "df_exl.to_excel(writer, sheet_name ='Sheet1') # Create sheet in Excel Files\n",
    "# Create sheet in Excel Files with Parameter\n",
    "df_exl.to_excel(writer, sheet_name ='Sheet1', startcol=2, startrow=3, header=False, index=False) \n",
    "writer.close()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# dataframe with datetimes to an Excel file with a default datetime and date format using Pandas and XlsxWriter\n",
    "df_dt = pd.DataFrame({  # dataframe created using some date and times data\n",
    "    'Date and time': [ \n",
    "        datetime(2018, 1, 11, 11, 30, 55),\n",
    "        datetime(2018, 2, 12, 1,  20, 33),\n",
    "        datetime(2018, 3, 13, 11, 10    ),\n",
    "        datetime(2018, 4, 14, 16, 45, 35),\n",
    "        datetime(2018, 5, 15, 12, 10, 15) ],\n",
    "    \n",
    "    'Dates only': [ \n",
    "        date(2018, 6, 21),\n",
    "        date(2018, 7, 22),\n",
    "        date(2018, 8, 23),\n",
    "        date(2018, 9, 24),\n",
    "        date(2018, 10, 25) ]\n",
    "})\n",
    "print(df_dt)\n",
    "print()\n",
    "\n",
    "writer = pd.ExcelWriter(\"Data/file_dt.xlsx\", engine ='xlsxwriter', \n",
    "                        datetime_format ='mmm d yyyy hh:mm:ss', date_format ='mmmm dd yyyy')\n",
    "df_dt.to_excel(writer, sheet_name ='Sheet1')\n",
    "workSheet  = writer.sheets['Sheet1']\n",
    "workSheet.set_column('B:C', 20) \n",
    "writer.close()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# # Dataframe to an Excel file with column formats using Pandas and XlsxWriter\n",
    "dataframe = pd.DataFrame(\n",
    "    {'Marks (Out of 50)': [30, 40, 45, 15, 8, 5, 35],\n",
    "     'Percentage': [.6,   .8,   .9,  .3,  .16,   .1,  .7 ], })\n",
    "\n",
    "writer = pd.ExcelWriter(\"Data/Test.xlsx\", engine ='xlsxwriter')\n",
    "dataframe.to_excel(writer, sheet_name ='Sheet1')\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "format_1 = workbook.add_format({'num_format': '# 0.00'}) # Create a new Format object to formats cells n worksheets using add_format() method\n",
    "format_2 = workbook.add_format({'num_format': '0 %'})\n",
    "   \n",
    "# NOTE: It isn't possible to format any cells that already have a format such as the index or headers or any\n",
    "# cells that contain dates or datetimes.\n",
    "worksheet.set_column('B:B', 20, format_1)\n",
    "worksheet.set_column('C:C', 15, format_2)\n",
    "writer.close()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# Dataframe to an Excel file with a user defined header format using Pandas and XlsxWriter\n",
    "df_xsl_plt = pd.DataFrame({\n",
    "    'Subject': [\"Math\", \"Physics\", \"Computer\", \"Hindi\", \"English\", \"chemistry\"],\n",
    "    'Mid Term Exam Scores Out of 100' : [95, 78, 80, 80, 60, 95],\n",
    "    'End Term Exam Scores Out of 100' : [90, 67, 78, 70, 63, 90]\n",
    "})\n",
    "writer = pd.ExcelWriter(\"Data/Test.xlsx\", engine ='xlsxwriter')\n",
    "df_xsl_plt.to_excel(writer, sheet_name ='Sheet2')\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets['Sheet2']\n",
    "\n",
    "hformate = workbook.add_format({ \n",
    "    'bold': True, \n",
    "    'italic' : True, \n",
    "    'text_wrap': True, \n",
    "    'valign': 'top',\n",
    "    'font_color': 'red',\n",
    "    'border': 2\n",
    "})\n",
    "for col_number, value in enumerate(dataframe.columns.values):\n",
    "    worksheet.write(0, col_number + 1, value, hformate)\n",
    "writer.close()\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "# Plot a Column chart using Pandas and XlsxWriter\n",
    "df_xsl_plt = pd.DataFrame({\n",
    "    'Subject': [\"Math\", \"Physics\", \"Computer\", \"Hindi\", \"English\", \"chemistry\"],\n",
    "    'Mid Exam Score' : [90, 78, 60, 80, 60, 90],\n",
    "    'End Exam Score' : [45, 39, 30, 40, 30, 60] \n",
    "})\n",
    "writer = pd.ExcelWriter('Data/Test.xlsx', engine ='xlsxwriter')\n",
    "df_xsl_plt.to_excel(writer, sheet_name ='Sheet1')\n",
    "workbook = writer.book\n",
    "\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "worksheet.set_column('B:C', 20)\n",
    "\n",
    "chart = workbook.add_chart({'type': 'column'})\n",
    "\n",
    "chart.add_series({\n",
    "    'name': ['Sheet1', 0, 2],\n",
    "    'categories': ['Sheet1', 1, 3, 6, 3],\n",
    "    'values': ['Sheet1', 1, 2, 6, 2]\n",
    "})\n",
    "\n",
    "chart.add_series({\n",
    "\t'name':\t ['Sheet1', 0, 1],\n",
    "\t'categories': ['Sheet1', 1, 3, 6, 3],\n",
    "\t'values': ['Sheet1', 1, 1, 6, 1]\n",
    "})\n",
    "\n",
    "chart.set_title({'name': 'Exam Score Distribution'})\n",
    "chart.set_x_axis({'name': 'Subjects'})\n",
    "chart.set_y_axis({'name': 'Marks'})\n",
    "worksheet.insert_chart('E2', chart, {'x_offset': 20, 'y_offset': 5})\n",
    "writer.close()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# Plot a Line chart using Pandas and XlsxWriter\n",
    "df_xsl_plt = pd.DataFrame({\n",
    "    'Mid Exam Score' : [90, 78, 60, 80, 60, 90],\n",
    "    'End Exam Score' : [45, 39, 30, 40, 30, 60],\n",
    "    'Subject': [\"Math\", \"Physics\", \"Computer\", \"Hindi\", \"English\", \"chemistry\"]\n",
    "})\n",
    "writer = pd.ExcelWriter('Data/Test.xlsx', engine ='xlsxwriter')\n",
    "df_xsl_plt.to_excel(writer, sheet_name ='Sheet1')\n",
    "workbook = writer.book\n",
    "\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "worksheet.set_column('B:C', 20)\n",
    "\n",
    "charts = workbook.add_chart({'type': 'line'})\n",
    "\n",
    "charts.add_series({\n",
    "    'name': ['Sheet1', 0, 2],\n",
    "    'categories': ['Sheet1', 1, 3, 6, 3],\n",
    "    'values': ['Sheet1', 1, 2, 6, 2]\n",
    "})\n",
    "\n",
    "charts.add_series({\n",
    "\t'name':\t ['Sheet1', 0, 1],\n",
    "\t'categories': ['Sheet1', 1, 3, 6, 3],\n",
    "\t'values': ['Sheet1', 1, 1, 6, 1]\n",
    "})\n",
    "\n",
    "charts.set_title({'name': 'Exam Score Distribution'})\n",
    "charts.set_x_axis({'name': 'Subjects'})\n",
    "charts.set_y_axis({'name': 'Marks'})\n",
    "worksheet.insert_chart('E2', charts, {'x_offset': 20, 'y_offset': 5})\n",
    "writer.close()\n",
    "print(\"=====================================================================================\")\n",
    "print()\n",
    "\n",
    "# Plot a scatter chart using Pandas and XlsxWriter\n",
    "df_xsl_plt = pd.DataFrame({\n",
    "    'Mid Exam Score' : [90, 78, 60, 80, 60, 90],\n",
    "    'End Exam Score' : [45, 39, 30, 40, 30, 60],\n",
    "    'Subject': [\"Math\", \"Physics\", \"Computer\", \"Hindi\", \"English\", \"chemistry\"]\n",
    "})\n",
    "writer = pd.ExcelWriter('Data/Test.xlsx', engine ='xlsxwriter')\n",
    "df_xsl_plt.to_excel(writer, sheet_name ='Sheet1')\n",
    "workbook = writer.book\n",
    "\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "worksheet.set_column('B:C', 20)\n",
    "\n",
    "charts = workbook.add_chart({'type': 'scatter'})\n",
    "\n",
    "charts.add_series({\n",
    "    'name': ['Sheet1', 0, 2],\n",
    "    'categories': ['Sheet1', 1, 3, 6, 3],\n",
    "    'values': ['Sheet1', 1, 2, 6, 2]\n",
    "})\n",
    "\n",
    "charts.add_series({\n",
    "\t'name':\t ['Sheet1', 0, 1],\n",
    "\t'categories': ['Sheet1', 1, 3, 6, 3],\n",
    "\t'values': ['Sheet1', 1, 1, 6, 1]\n",
    "})\n",
    "\n",
    "charts.set_title({'name': 'Exam Score Distribution'})\n",
    "charts.set_x_axis({'name': 'Subjects'})\n",
    "charts.set_y_axis({'name': 'Marks'})\n",
    "worksheet.insert_chart('E2', charts, {'x_offset': 20, 'y_offset': 5})\n",
    "writer.close()\n",
    "\n",
    "print(\"=====================================================================================\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylibs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
